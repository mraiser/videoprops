mkdir llama-cpp-python
cd llama-cpp-python
ln -s ../llama.cpp/models models
python -m venv venv
source venv/bin/activate
CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python[server]
python3 -m llama_cpp.server --model models/dolphin-2.1-mistral-7b.Q4_0.gguf 

cd /home/mraiser/ai/chuckme/autogen
nix-shell --run 'source venv/bin/activate; python agengtchat.py'
